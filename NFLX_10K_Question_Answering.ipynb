{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44fbd1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import numpy as np\n",
    "import pickle\n",
    "import docx\n",
    "from transformers import GPT2TokenizerFast\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e8f40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = 'YOUR OPENAI API KEY'\n",
    "COMPLETIONS_MODEL = \"text-davinci-003\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f836ae7d",
   "metadata": {},
   "source": [
    "## 1) Extract the text from the 10Q report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37371279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(filename, tokenizer):\n",
    "    doc = docx.Document(filename)\n",
    "    full_text = ['']\n",
    "    for para in doc.paragraphs:  # Loop through each chunk of text\n",
    "        text = unicodedata.normalize(\"NFKD\", para.text.replace(\"\\n\", \"\")).strip() # Clean up the text  \n",
    "        num_tokens = len(tokenizer.tokenize(text)) # Measure how long the chunk is\n",
    "        is_header = text == text.title() # Check if this chunk is a section header\n",
    "        if is_header: # Omit section headers\n",
    "            continue\n",
    "        if num_tokens > 28: # if the text is large enough, consider it a chunk\n",
    "            full_text.append(text)\n",
    "        else:\n",
    "            full_text[-1] += f\"\\n{text}\".strip() # Otherwise, append it to the previous chunk as it likely belongs with it\n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "206c56fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can download the 10Q report from here:\n",
    "# https://ir.netflix.net/financials/sec-filings/default.aspx. I downloaded and saved it in my computer as netflix_10Q.docx\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "text = get_text(\"netflix_10K.docx\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bae03c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Table of ContentsPART I</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>other impediments to delivering our streaming ...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>The long-term and largely fixed cost nature of...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>(9)Registration Statement (Form S-8 No. 333-23...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>(6)Registration Statement (Form S-8 No. 333-14...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>The Company has entered into operating leases ...</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>As a producer and distributor of content, we f...</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This Annual Report on Form 10-K contains forwa...</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>We have a substantial amount of indebtedness a...</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>If consumers do not perceive our service offer...</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>394 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             paragraph token_count\n",
       "0                              Table of ContentsPART I           5\n",
       "40   other impediments to delivering our streaming ...          29\n",
       "72   The long-term and largely fixed cost nature of...          29\n",
       "358  (9)Registration Statement (Form S-8 No. 333-23...          29\n",
       "356  (6)Registration Statement (Form S-8 No. 333-14...          29\n",
       "..                                                 ...         ...\n",
       "221  The Company has entered into operating leases ...         380\n",
       "31   As a producer and distributor of content, we f...         389\n",
       "1    This Annual Report on Form 10-K contains forwa...         444\n",
       "76   We have a substantial amount of indebtedness a...         475\n",
       "23   If consumers do not perceive our service offer...         501\n",
       "\n",
       "[394 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=[text, pd.Series(text).apply(lambda p: len(tokenizer.tokenize(p)))]).T\n",
    "df.columns = ['paragraph', 'token_count']\n",
    "df.sort_values(by=\"token_count\") # We broke up the report into 158 chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4e1db50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Company acquires, licenses and produces content, including original programming, in order to offer members unlimited viewing of video entertainment. The content licenses are for a fixed fee and specific windows of availability. Payment terms for certain content licenses and the production of content require more upfront cash payments relative to the amortization expense. Payments for content, including additions to content assets and the changes in related liabilities, are classified within \"Net cash provided by (used in) operating activities\" on the Consolidated Statements of Cash Flows.\n"
     ]
    }
   ],
   "source": [
    "# Let's look at a sample chunk\n",
    "print(df.loc[200]['paragraph']) # This is useful information!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a1494a",
   "metadata": {},
   "source": [
    "## 2) Create an embedding vector for each paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "593d9b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this code is taken from https://github.com/openai/openai-cookbook and was slightly modified\n",
    "MODEL_NAME = \"curie\" # Very good for the task\n",
    "DOC_EMBEDDINGS_MODEL = f\"text-search-{MODEL_NAME}-doc-001\"\n",
    "QUERY_EMBEDDINGS_MODEL = f\"text-search-{MODEL_NAME}-query-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f050d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str, model: str) -> list[float]:\n",
    "    result = openai.Embedding.create(\n",
    "      model=model,\n",
    "      input=text\n",
    "    )\n",
    "    return result[\"data\"][0][\"embedding\"]\n",
    "\n",
    "def get_doc_embedding(text: str) -> list[float]:\n",
    "    return get_embedding(text, DOC_EMBEDDINGS_MODEL)\n",
    "\n",
    "def get_query_embedding(text: str) -> list[float]:\n",
    "    return get_embedding(text, QUERY_EMBEDDINGS_MODEL)\n",
    "\n",
    "def compute_doc_embeddings(df: pd.DataFrame) -> dict[tuple[str, str], list[float]]:\n",
    "    \"\"\"\n",
    "    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
    "\n",
    "    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
    "    \"\"\"\n",
    "    embeddings_fn = \"nflx_10k_embeddings.pkl\"\n",
    "    try:\n",
    "        embeddings = pickle.load(open(embeddings_fn, \"rb\"))\n",
    "    except (OSError, IOError) as e:\n",
    "        embeddings = {}\n",
    "        pickle.dump(embeddings, open(embeddings_fn, \"wb\"))\n",
    "    \n",
    "    for idx, r in tqdm(df.iterrows()):\n",
    "        if idx not in embeddings:\n",
    "            embeddings[idx] = get_doc_embedding(r['paragraph'].replace(\"\\n\", \" \"))\n",
    "            pickle.dump(embeddings, open(embeddings_fn, 'wb'))\n",
    "            sleep(0.5)\n",
    "    return embeddings\n",
    "\n",
    "def load_embeddings(fname: str) -> dict[tuple[str, str], list[float]]:\n",
    "    \"\"\"\n",
    "    Read the document embeddings and their keys from a CSV.\n",
    "    \n",
    "    fname is the path to a CSV with exactly these named columns: \n",
    "        \"title\", \"heading\", \"0\", \"1\", ... up to the length of the embedding vectors.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(fname, header=0)\n",
    "    max_dim = max([int(c) for c in df.columns if c != \"title\" and c != \"heading\"])\n",
    "    return {\n",
    "           (r.title, r.heading): [r[str(i)] for i in range(max_dim + 1)] for _, r in df.iterrows()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e0f97fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [04:53,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "document_embeddings = compute_doc_embeddings(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340a6479",
   "metadata": {},
   "source": [
    "## 3) Construct the GPT-3 prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915f84bc",
   "metadata": {},
   "source": [
    "### Step 1: Find the paragraphs that are mostly related to the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b136a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_similarity(x: list[float], y: list[float]) -> float:\n",
    "    \"\"\"\n",
    "    We could use cosine similarity or dot product to calculate the similarity between vectors.\n",
    "    \"\"\"\n",
    "    return np.dot(np.array(x), np.array(y))\n",
    "\n",
    "def order_document_sections_by_query_similarity(query, contexts):\n",
    "    \"\"\"\n",
    "    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\n",
    "    to find the most relevant sections. \n",
    "    \n",
    "    Return the list of document sections, sorted by relevance in descending order.\n",
    "    \"\"\"\n",
    "    query_embedding = get_query_embedding(query)\n",
    "    \n",
    "    document_similarities = sorted([\n",
    "        (vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items()\n",
    "    ], reverse=True)\n",
    "    \n",
    "    return document_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e8a318",
   "metadata": {},
   "source": [
    "### Step 2: Add the most relevant paragraphs (context) to the query, and make GPT-3 answer based on the context provided only \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c20f3c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SECTION_LEN = 1000\n",
    "SEPARATOR = \"\\n* \"\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "separator_len = len(tokenizer.tokenize(SEPARATOR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "299a567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(question: str, context_embeddings: dict, df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Fetch relevant \n",
    "    \"\"\"\n",
    "    most_relevant_document_sections = order_document_sections_by_query_similarity(question, context_embeddings)\n",
    "    \n",
    "    chosen_sections = []\n",
    "    chosen_sections_len = 0\n",
    "    chosen_sections_indexes = []\n",
    "     \n",
    "    for _, section_index in most_relevant_document_sections:\n",
    "        # Add contexts until we run out of space.        \n",
    "        document_section = df.loc[section_index]\n",
    "        \n",
    "        chosen_sections_len += document_section['token_count'] + separator_len\n",
    "        if chosen_sections_len > MAX_SECTION_LEN:\n",
    "            break\n",
    "            \n",
    "        chosen_sections.append(SEPARATOR + document_section['paragraph'].replace(\"\\n\", \" \"))\n",
    "        chosen_sections_indexes.append(str(section_index))\n",
    "    \n",
    "    header = \"\"\"Answer the question as truthfully as possible using the provided context on the company Netflix, and if the answer is not contained within the context below, say \"Answer is not found.\"\\n\\nContext:\\n\"\"\"\n",
    "    \n",
    "    return header + \"\".join(chosen_sections) + \"\\n\\n Q: \" + question + \"\\n A:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f57f1633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the question as truthfully as possible using the provided context on the company Netflix, and if the answer is not contained within the context below, say \"Answer is not found.\"\n",
      "\n",
      "Context:\n",
      "\n",
      "* From time to time, we acquire or invest in businesses, content, and technologies that support our business. The risks associated with such acquisitions or investments include the difficulty of integrating solutions, operations, and personnel; inheriting liabilities and exposure to litigation; failure to realize anticipated benefits and expected synergies; and diversion of management’s time and attention, among other acquisition-related risks.\n",
      "* We face risks, such as unforeseen costs and potential liability in connection with content we acquire, produce, license and/or distribute through our service.\n",
      "* from any liability or unforeseen production risks could harm our results of operations. We may not be indemnified against claims or costs of these types and we may not have insurance coverage for these types of claims.If we are not able to manage change and growth, our business could be adversely affected.\n",
      "* If any of the following risks actually occur, our business, financial condition and results of operations could be harmed. In that case, the trading price of our common stock could decline, and you could lose all or part of your investment.Risks Related to Our BusinessIf our efforts to attract and retain members are not successful, our business will be adversely affected.\n",
      "* Operating in international markets requires significant resources and management attention and will subject us to economic, political, regulatory and other risks that may be different from or incremental to those in the U.S. In addition to the risks that we face in the U.S., our international operations involve risks that could adversely affect our business, including:•the need to adapt our content and user interfaces for specific cultural and language differences;•difficulties and costs associated with staffing and managing foreign operations;•political or social unrest and economic instability;\n",
      "* We may not be successful in overcoming such risks, and such acquisitions and investments may negatively impact our business. In addition, if we do not complete an announced acquisition transaction or integrate an acquired business successfully and in a timely manner, we may not realize the benefits of the acquisition to the extent anticipated. Acquisitions and investments may contribute to fluctuations in our quarterly financial results. These fluctuations could arise from transaction-related costs and charges associated with eliminating redundant expenses or write-offs of impaired assets recorded in connection with acquisitions and investments, and could negatively impact our financial results.We rely upon a number of partners to make our service available on their devices.\n",
      "* If the technology we use in operating our business fails, is unavailable, or does not operate to expectations, our business and results of operation could be adversely impacted.\n",
      "* To the extent we do not accurately anticipate costs or mitigate risks, including for content that we obtain but ultimately does not appear on or is removed from our service, or if we become liable for content we acquire, produce, license and/or distribute, our business may suffer. Litigation to defend these claims could be costly and the expenses and damages arising\n",
      "* If our cash flows are insufficient to fund our debt and other obligations and we are unable to refinance or restructure these obligations, we could face substantial liquidity problems and may be forced to reduce or delay investments and capital expenditures, or to sell material assets or operations to meet our debt and other obligations. We cannot assure you that we would be able to implement any of these alternative measures on satisfactory terms or at all or that the proceeds from such alternatives would be adequate to meet any debt or other obligations when due. If it becomes necessary to implement any of these alternative measures, our business, results of operations, or financial condition could be materially and adversely affected.Risks Related to International OperationsWe could be subject to economic, political, regulatory and other risks arising from our international operations.\n",
      "* •fluctuations in currency exchange rates, which we do not use foreign exchange contracts or derivatives to hedge against and which will impact revenues and expenses of our international operations and expose us to foreign currency exchange rate risk;•profit repatriation and other restrictions on the transfer of funds;•differing payment processing systems as well as consumer use and acceptance of electronic payment methods, such as payment cards;•new and different sources of competition;•censorship requirements that cause us to remove or edit popular content, leading to consumer disappointment, brand tarnishment or dissatisfaction with our service;•low usage and/or penetration of internet-connected consumer electronic devices;\n",
      "* Any significant disruption in or unauthorized access to our computer systems or those of third parties that we utilize in our operations, including those relating to cybersecurity or arising from cyber-attacks, could result in a loss or degradation of service, unauthorized disclosure of data, including member and corporate information, or theft of intellectual property, including digital content assets, which could adversely impact our business.\n",
      "\n",
      " Q: What are they major risks for the business?\n",
      " A:\n"
     ]
    }
   ],
   "source": [
    "prompt = construct_prompt(\n",
    "    \"What are they major risks for the business?\",\n",
    "    document_embeddings,\n",
    "    df\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79685801",
   "metadata": {},
   "source": [
    "## 3) Answer the user's question based on the context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a715f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETIONS_API_PARAMS = {\n",
    "    # We use temperature of 0.0 because it gives the most predictable, factual answer.\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_tokens\": 1200,\n",
    "    \"model\": COMPLETIONS_MODEL,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb5b60d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query_with_context(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    document_embeddings: dict[(str, str), np.array],\n",
    "    show_prompt: bool = False\n",
    ") -> str:\n",
    "    prompt = construct_prompt(\n",
    "        query,\n",
    "        document_embeddings,\n",
    "        df\n",
    "    )\n",
    "    \n",
    "    if show_prompt:\n",
    "        print(prompt)\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "                prompt=prompt,\n",
    "                **COMPLETIONS_API_PARAMS\n",
    "            )\n",
    "\n",
    "    return response[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dea0cc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Major risks for Netflix include the expiration of agreements with partners, consumer dissatisfaction, payment processing risk, unforeseen costs and potential liability in connection with content, technological or business-related disruptions, cybersecurity threats, regulatory interference, failure to protect domain names, potential liability for negligence, copyright and trademark infringement, and risks associated with production.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_query_with_context(\"What are the major risks for Netflix?\", df, document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85be7c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Failure to protect our domain names could adversely affect our reputation and brand and make it more difficult for users to find our website and our service. We may be unable, without significant cost or at all, to prevent third parties from acquiring domain names that are similar to, infringe upon or otherwise decrease the value of our trademarks and other proprietary rights.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_query_with_context(\"Explain to me the risk of failure to protect domain names\", df, document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f1a5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
